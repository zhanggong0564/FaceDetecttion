{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanggong/miniconda3/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    " \n",
    "class ConvWithBn(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(ConvWithBn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1, bias=False) \n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self._initialize_weights()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        return x\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(0, 1)\n",
    "                m.bias.data.normal_(0, 1)\n",
    "                m.running_mean.data.normal_(0, 1)\n",
    "                m.running_var.data.uniform_(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1, bias=False) \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvWithBias(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(ConvWithBias, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1, bias=True) \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model1 = ConvWithBn()\n",
    "model1_cpkt = Model1.state_dict()\n",
    "Model1.eval()\n",
    "Model2 = Conv()\n",
    "model2_cpkt = {k:v for k,v in model1_cpkt.items() if k in Model2.state_dict()}\n",
    "Model2.load_state_dict(model2_cpkt)\n",
    "Model2.eval()\n",
    " \n",
    "input = torch.randn(1,3,64,64)\n",
    "out1 = Model1(input)\n",
    "out2 = Model2(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1019, -0.3648, -0.2868,  ..., -0.7173, -0.4325,  0.0201],\n",
       "        [-0.2780, -0.2512,  0.1077,  ..., -0.6277, -0.0932, -0.3593],\n",
       "        [-0.2696, -0.4547,  0.0357,  ...,  0.3470,  0.1927, -0.0093],\n",
       "        ...,\n",
       "        [-0.2300, -0.5385, -0.3354,  ..., -0.2428, -0.1889, -0.0223],\n",
       "        [-0.1480,  0.1193, -0.4314,  ..., -0.0821, -0.3396, -0.2906],\n",
       "        [-0.1546, -0.2099, -0.0995,  ..., -0.3481, -0.2938, -0.1365]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3194, -0.8087, -0.4742,  ..., -2.3212, -1.0992,  0.8427],\n",
       "        [-0.4362, -0.3214,  1.2184,  ..., -1.9368,  0.3565, -0.7853],\n",
       "        [-0.4002, -1.1945,  0.9098,  ...,  2.2455,  1.5834,  0.7164],\n",
       "        ...,\n",
       "        [-0.2304, -1.5539, -0.6827,  ..., -0.2854, -0.0539,  0.6607],\n",
       "        [ 0.1212,  1.2685, -1.0948,  ...,  0.4041, -0.7006, -0.4904],\n",
       "        [ 0.0931, -0.1442,  0.3294,  ..., -0.7373, -0.5042,  0.1707]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_cpkt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_cpkt['bn1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnw = model1_cpkt['bn1.weight']\n",
    "bnb = model1_cpkt['bn1.bias']\n",
    "mean = model1_cpkt['bn1.running_mean']\n",
    "var = model1_cpkt['bn1.running_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnwexp = bnw.unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
    "bnbexp = bnb.unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
    "meanexp = mean.unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
    "varexp = var.unsqueeze(0).unsqueeze(2).unsqueeze(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnout = bnwexp*((out2 - meanexp)/torch.sqrt(varexp+1e-5)) +bnbexp\n",
    "torch.sum(bnout - out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnwexp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model3 = ConvWithBias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1w = model1_cpkt['conv1.weight']\n",
    "bnw = model1_cpkt['bn1.weight']\n",
    "bnb = model1_cpkt['bn1.bias']\n",
    "bnmean = model1_cpkt['bn1.running_mean']\n",
    "bnvar = model1_cpkt['bn1.running_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnwexp = bnw.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "bnvarexp = bnvar.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "new_conv1w = (bnwexp*conv1w)/(torch.sqrt(bnvarexp+1e-5))\n",
    "new_conv2b = (bnb - bnw*bnmean/(torch.sqrt(bnvar+1e-5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnwexp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_state_dict = {}\n",
    "merge_state_dict['conv1.weight'] = new_conv1w\n",
    "merge_state_dict['conv1.bias'] = new_conv2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias of merged ConvBn :  tensor(-0.0002, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Model3.load_state_dict(merge_state_dict)\n",
    "\n",
    "Model3.eval()\n",
    "out3 = Model3(input)\n",
    "print(\"Bias of merged ConvBn : \",torch.sum(out3 - out1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\"\"\"  Parameters and variables  \"\"\"\n",
    "IMAGENET = '/home/zym/ImageNet/ILSVRC2012_img_val_256xN_list.txt'\n",
    "LABEL = '/home/zym/ImageNet/synset.txt'\n",
    "TEST_ITER = 10\n",
    "SAVE = False\n",
    "TEST_AFTER_MERGE = True\n",
    "\n",
    "\n",
    "\"\"\"  Functions  \"\"\"\n",
    "def merge(params, name, layer):\n",
    "    # global variables\n",
    "    global weights, bias\n",
    "    global bn_param\n",
    "\n",
    "    if layer == 'Convolution':\n",
    "        # save weights and bias when meet conv layer\n",
    "        if 'weight' in name:\n",
    "            weights = params.data\n",
    "            bias = torch.zeros(weights.size()[0])\n",
    "        elif 'bias' in name:\n",
    "            bias = params.data\n",
    "        bn_param = {}\n",
    "\n",
    "    elif layer == 'BatchNorm':\n",
    "        # save bn params\n",
    "        bn_param[name.split('.')[-1]] = params.data\n",
    "\n",
    "        # running_var is the last bn param in pytorch\n",
    "        if 'running_var' in name:\n",
    "            # let us merge bn ~\n",
    "            tmp = bn_param['weight'] / torch.sqrt(bn_param['running_var'] + 1e-5)\n",
    "            weights = tmp.view(tmp.size()[0], 1, 1, 1) * weights\n",
    "            bias = tmp*(bias - bn_param['running_mean']) + bn_param['bias']\n",
    "\n",
    "            return weights, bias\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "\"\"\"  Main functions  \"\"\"\n",
    "# import pytorch model\n",
    "import models.shufflenetv2.shufflenetv2_merge as shufflenetv2\n",
    "pytorch_net = shufflenetv2.ShuffleNetV2().eval()\n",
    "model_path = shufflenetv2.weight_file\n",
    "\n",
    "# load weights\n",
    "print('Finding trained model weights...')\n",
    "try:\n",
    "    for file in os.listdir(model_path):\n",
    "        if 'pth' in file:\n",
    "            print('Loading weights from %s ...' % file)\n",
    "            trained_weights = torch.load(os.path.join(model_path, file))\n",
    "            # pytorch_net.load_state_dict(trained_weights)\n",
    "            print('Weights load success')\n",
    "            break\n",
    "except:\n",
    "    raise ValueError('No trained model found or loading error occurs')\n",
    "\n",
    "# go through pytorch net\n",
    "print('Going through pytorch net weights...')\n",
    "new_weights = OrderedDict()\n",
    "inner_product_flag = False\n",
    "for name, params in trained_weights.items():\n",
    "    if len(params.size()) == 4:\n",
    "        _, _ = merge(params, name, 'Convolution')\n",
    "        prev_layer = name\n",
    "    elif len(params.size()) == 1 and not inner_product_flag:\n",
    "        w, b = merge(params, name, 'BatchNorm')\n",
    "        if w is not None:\n",
    "            new_weights[prev_layer] = w\n",
    "            new_weights[prev_layer.replace('weight', 'bias')] = b\n",
    "    else:\n",
    "        # inner product layer\n",
    "        # if meet inner product layer,\n",
    "        # the next bias weight can be misclassified as 'BatchNorm' layer as len(params.size()) == 1\n",
    "        new_weights[name] = params\n",
    "        inner_product_flag = True\n",
    "\n",
    "# align names in new_weights with pytorch model\n",
    "# after move BatchNorm layer in pytorch model,\n",
    "# the layer names between old model and new model will mis-align\n",
    "print('Aligning weight names...')\n",
    "pytorch_net_key_list = list(pytorch_net.state_dict().keys())\n",
    "new_weights_key_list = list(new_weights.keys())\n",
    "assert len(pytorch_net_key_list) == len(new_weights_key_list)\n",
    "for index in range(len(pytorch_net_key_list)):\n",
    "    new_weights[pytorch_net_key_list[index]] = new_weights.pop(new_weights_key_list[index])\n",
    "\n",
    "# save new weights\n",
    "if SAVE:\n",
    "    torch.save(new_weights, model_path + '/' + file.replace('.pth', '_merged.pth'))\n",
    "\n",
    "# test merged pytorch model\n",
    "if TEST_AFTER_MERGE:\n",
    "    try:\n",
    "        pytorch_net.load_state_dict(new_weights)\n",
    "        print('Pytorch net load weights success~')\n",
    "    except:\n",
    "        raise ValueError('Load new weights error')\n",
    "\n",
    "    print('-' * 50)\n",
    "    with open(LABEL) as f:\n",
    "        labels = f.read().splitlines()\n",
    "    with open(IMAGENET) as f:\n",
    "        images = f.read().splitlines()\n",
    "        for _ in range(TEST_ITER):\n",
    "            # cv2 default chann el is BGR\n",
    "            image_path, label = images[np.random.randint(0, len(images))].split(' ')\n",
    "            # image_path, label = images[0].split(' ')\n",
    "            input_image = cv2.imread(image_path)\n",
    "            input_image = cv2.resize(input_image, (224, 224))\n",
    "            input_image = transforms.Compose([transforms.ToTensor(),\n",
    "                                              transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                   std=[0.229, 0.224, 0.225])\n",
    "                                              ])(input_image)\n",
    "            input_image = input_image.view(1, 3, 224, 224)\n",
    "            output_logits = pytorch_net(input_image)\n",
    "            _, index = output_logits.max(dim=1)\n",
    "            print('true label: \\t%s' % labels[int(label)])\n",
    "            print('predict label:\\t%s' % labels[int(index)])\n",
    "            print('-' * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "899241f4a75379447975d1af63d8c8aabee7d16326bb0b2b173a2507dd9ad7e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
